{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Fe0kzfMOspx"
   },
   "source": [
    "## 第5章: 係り受け解析\n",
    "日本語Wikipediaの「人工知能」に関する記事からテキスト部分を抜き出したファイルがai.ja.zipに収録されている． この文章をCaboChaやKNP等のツールを利用して係り受け解析を行い，その結果をai.ja.txt.parsedというファイルに保存せよ．このファイルを読み込み，以下の問に対応するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmd2sAqPOwwx"
   },
   "source": [
    "まずは指定のデータをダウンロードします。\n",
    "Google Colaboratoryのセル上で下記のコマンドを実行すると、カレントディレクトリに対象のファイルがダウンロードされます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1610683749836,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "7Y7_Sax-OqXe",
    "outputId": "92175cd7-4c0d-4bd0-b399-2b2eace1ef80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-11 10:25:59--  https://nlp100.github.io/data/ai.ja.zip\n",
      "Resolving nlp100.github.io (nlp100.github.io)... 185.199.111.153, 185.199.110.153, 185.199.108.153, ...\n",
      "Connecting to nlp100.github.io (nlp100.github.io)|185.199.111.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17516 (17K) [application/zip]\n",
      "Saving to: ‘ai.ja.zip’\n",
      "\n",
      "ai.ja.zip           100%[===================>]  17.11K  82.6KB/s    in 0.2s    \n",
      "\n",
      "2021-12-11 10:25:59 (82.6 KB/s) - ‘ai.ja.zip’ saved [17516/17516]\n",
      "\n",
      "/usr/bin/sh: 1: unzip: not found\n"
     ]
    }
   ],
   "source": [
    "!wget https://nlp100.github.io/data/ai.ja.zip\n",
    "!unzip ai.ja.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2JOuZj9O4-U"
   },
   "source": [
    "CaboChaおよびCaboChaの実行に必要なMeCabとCRF++をインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61567,
     "status": "ok",
     "timestamp": 1610683822579,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "goLsl2mOO6WP",
    "outputId": "3c01d751-c0e8-43af-c907-e8eabb3a22cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-11 10:26:01--  https://docs.google.com/uc?export=download&id=$FILE_ID\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.76.142, 2404:6800:4004:824::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.76.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2021-12-11 10:26:02 ERROR 404: Not Found.\n",
      "\n",
      "tar: This does not look like a tar archive\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "tar: Child returned status 1\n",
      "tar: Error is not recoverable: exiting now\n",
      "[Errno 2] No such file or directory: 'CRF++-0.58'\n",
      "/work/notebooks\n",
      "/usr/bin/sh: 1: ./configure: not found\n",
      "/work\n"
     ]
    }
   ],
   "source": [
    "# CRF++のソースファイルのダウンロード・解凍・インストール\n",
    "FILE_ID = \"0B4y35FiV1wh7QVR6VXJ5dWExSTQ\"\n",
    "FILE_NAME = \"crfpp.tar.gz\"\n",
    "!wget 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O $FILE_NAME\n",
    "!tar xvf crfpp.tar.gz\n",
    "%cd CRF++-0.58\n",
    "!./configure && make && make install && ldconfig\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 189509,
     "status": "ok",
     "timestamp": 1610683960797,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "z0m6aJb-O8FT",
    "outputId": "d62f5b6f-4b2f-40d5-af75-cae5dcdc98bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-11 10:26:06--  https://docs.google.com/uc?export=download&confirm=&id=0B4y35FiV1wh7SDd1Q1dUQkZQaUU\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.76.142, 2404:6800:4004:824::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.76.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘cabocha-0.69.tar.bz2’\n",
      "\n",
      "cabocha-0.69.tar.bz     [ <=>                ]   3.20K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2021-12-11 10:26:06 (136 KB/s) - ‘cabocha-0.69.tar.bz2’ saved [3281]\n",
      "\n",
      "bzip2: (stdin) is not a bzip2 file.\n",
      "tar: Child returned status 2\n",
      "tar: Error is not recoverable: exiting now\n",
      "[Errno 2] No such file or directory: 'cabocha-0.69'\n",
      "/work\n",
      "/usr/bin/sh: 1: ./configure: not found\n",
      "/\n"
     ]
    }
   ],
   "source": [
    "# CaboChaのソースファイルのダウンロード・解凍・インストール\n",
    "FILE_ID = \"0B4y35FiV1wh7SDd1Q1dUQkZQaUU\"\n",
    "FILE_NAME = \"cabocha-0.69.tar.bz2\"\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$FILE_ID\" -O $FILE_NAME && rm -rf /tmp/cookies.txt\n",
    "!tar -xvf cabocha-0.69.tar.bz2\n",
    "%cd cabocha-0.69\n",
    "!./configure -with-charset=utf-8 && make && make check && make install && ldconfig\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVmt_o2APBJ4"
   },
   "source": [
    "係り受け解析を行います。\n",
    "以下のコマンドを実行することにより、ai.ja.txtを係り受け解析した結果が、ai.ja.txt.parsedとして出力されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 166149,
     "status": "ok",
     "timestamp": 1610683961213,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "LQdG5EspO-l3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: cabocha: not found\n"
     ]
    }
   ],
   "source": [
    "!cabocha -f1 -o ai.ja.txt.parsed ai.ja.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yu697M-0PF13"
   },
   "source": [
    "出力結果を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154466,
     "status": "ok",
     "timestamp": 1610683961213,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "S4pL_pkZPEZX",
    "outputId": "7bbf61e9-b386-4120-dc2a-b10a32df8f30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: ./ai.ja.txt.parsed: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# 行数の確認\n",
    "!wc -l ./ai.ja.txt.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 139862,
     "status": "ok",
     "timestamp": 1610683961214,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "ajdU_UuaPHP2",
    "outputId": "4fc5012a-8bb9-4c96-f00a-8f1be56024d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open './ai.ja.txt.parsed' for reading: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# 先頭15行の確認\n",
    "!head -15 ./ai.ja.txt.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pmuMPKpPVeu"
   },
   "source": [
    "#### 40. 係り受け解析結果の読み込み（形態素）\n",
    "形態素を表すクラスMorphを実装せよ．このクラスは表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をメンバ変数に持つこととする．さらに，係り受け解析の結果（ai.ja.txt.parsed）を読み込み，各文をMorphオブジェクトのリストとして表現し，冒頭の説明文の形態素列を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 82958,
     "status": "ok",
     "timestamp": 1610683961214,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "e2GKOiPDPK0I"
   },
   "outputs": [],
   "source": [
    "class Morph:\n",
    "    def __init__(self, morph):\n",
    "        surface, attr = morph.split(\"\\t\")\n",
    "        attr = attr.split(\",\")\n",
    "        self.surface = surface\n",
    "        self.base = attr[6]\n",
    "        self.pos = attr[0]\n",
    "        self.pos1 = attr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75482,
     "status": "ok",
     "timestamp": 1610683961215,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "_ziCPBVbPYtN",
    "outputId": "0eba9127-c24f-4bef-9e83-3dba23464920"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ai.ja.txt.parsed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_209/3468861849.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmorphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 係り受け関係を表す行：スキップ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ai.ja.txt.parsed'"
     ]
    }
   ],
   "source": [
    "filename = './ai.ja.txt.parsed'\n",
    "\n",
    "sentences = []\n",
    "morphs = []\n",
    "with open(filename, mode='r') as f:\n",
    "  for line in f:\n",
    "    if line[0] == '*':  # 係り受け関係を表す行：スキップ\n",
    "      continue\n",
    "    elif line != 'EOS\\n':  # 文末以外：Morphを適用し形態素リストに追加\n",
    "      morphs.append(Morph(line))\n",
    "    else:  # 文末：形態素リストを文リストに追加\n",
    "      sentences.append(morphs)\n",
    "      morphs = []\n",
    "\n",
    "# 確認\n",
    "for m in sentences[2]:\n",
    "  print(vars(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gnx-7ZqPcu8"
   },
   "source": [
    "#### 41. 係り受け解析結果の読み込み（文節・係り受け）\n",
    "40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストの係り受け解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，冒頭の説明文の文節の文字列と係り先を表示せよ．本章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CKOpI5IPggO"
   },
   "source": [
    "文章は文(sentence)オブジェクトのリストで表され、文オブジェクトは文節(chunk)オブジェクトのリストを要素に持ち、文節オブジェクトは形態素(morph)オブジェクトのリストを要素に持つ階層構造を考え、ここでは指定のクラスChunkに加え、Sentenceを実装しています。\n",
    "なお、Chunkオブジェクトの要素である係り元文節インデックス番号のリスト(srcs)の作成には1文のすべての文節情報を必要とするため、Sentenceオブジェクトの初期化時に作成しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1610685283993,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "szrQ7-0KUvcM"
   },
   "outputs": [],
   "source": [
    "class Chunk():\n",
    "  def __init__(self, morphs, dst):\n",
    "    self.morphs = morphs\n",
    "    self.dst = dst\n",
    "    self.srcs = []\n",
    "\n",
    "\n",
    "class Sentence():\n",
    "  def __init__(self, chunks):\n",
    "    self.chunks = chunks\n",
    "    for i, chunk in enumerate(self.chunks):\n",
    "      if chunk.dst != -1:\n",
    "        self.chunks[chunk.dst].srcs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1610684391355,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "rqCIRJM3PaiE"
   },
   "outputs": [],
   "source": [
    "class Morph:\n",
    "    def __init__(self, dc):\n",
    "        self.surface = dc['surface']\n",
    "        self.base = dc['base']\n",
    "        self.pos = dc['pos']\n",
    "        self.pos1 = dc['pos1']\n",
    "\n",
    "\n",
    "class Chunk:\n",
    "    def __init__(self, morphs, dst):\n",
    "        self.morphs = morphs    # 形態素（Morphオブジェクト）のリスト\n",
    "        self.dst = dst          # 係り先文節インデックス番号\n",
    "        self.srcs = []          # 係り元文節インデックス番号のリスト\n",
    "\n",
    "\n",
    "def parse_cabocha(block):\n",
    "    def check_create_chunk(tmp):\n",
    "        if len(tmp) > 0:\n",
    "            c = Chunk(tmp, dst)\n",
    "            res.append(c)\n",
    "            tmp = []\n",
    "        return tmp\n",
    "\n",
    "    res = []\n",
    "    tmp = []\n",
    "    dst = None\n",
    "    for line in block.split('\\n'):\n",
    "        if line == '':\n",
    "            tmp = check_create_chunk(tmp)\n",
    "        elif line[0] == '*':\n",
    "            dst = line.split(' ')[2].rstrip('D')\n",
    "            tmp = check_create_chunk(tmp)\n",
    "        else:\n",
    "            (surface, attr) = line.split('\\t')\n",
    "            attr = attr.split(',')\n",
    "            lineDict = {\n",
    "                'surface': surface,\n",
    "                'base': attr[6],\n",
    "                'pos': attr[0],\n",
    "                'pos1': attr[1]\n",
    "            }\n",
    "            tmp.append(Morph(lineDict))\n",
    "\n",
    "    for i, r in enumerate(res):\n",
    "        res[int(r.dst)].srcs.append(i)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1813,
     "status": "ok",
     "timestamp": 1610684469881,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "1UG_ssPCPhsG",
    "outputId": "ab8d7556-9231-4573-95bf-53de8b2f4c17"
   },
   "outputs": [],
   "source": [
    "filename = './ai.ja.txt.parsed'\n",
    "with open(filename, mode='r', encoding='utf-8') as f:\n",
    "    blocks = f.read().split('EOS\\n')\n",
    "blocks = list(filter(lambda x: x != '', blocks))\n",
    "blocks = [parse_cabocha(block) for block in blocks]\n",
    "for m in blocks[7]:\n",
    "    print([mo.surface for mo in m.morphs], m.dst, m.srcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3r2t72gPncU"
   },
   "source": [
    "#### 42. 係り元と係り先の文節の表示\n",
    "係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1600,
     "status": "ok",
     "timestamp": 1610684561669,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "G1LB4hiLPkx6",
    "outputId": "d552e6d8-657c-474f-9495-2089c99981f0"
   },
   "outputs": [],
   "source": [
    "filename = './ai.ja.txt.parsed'\n",
    "with open(filename, mode='r', encoding='utf-8') as f:\n",
    "    blocks = f.read().split('EOS\\n')\n",
    "blocks = list(filter(lambda x: x != '', blocks))\n",
    "blocks = [parse_cabocha(block) for block in blocks]\n",
    "\n",
    "for b in blocks:\n",
    "    for m in b:\n",
    "        if int(m.dst) > -1:\n",
    "            print(''.join([mo.surface if mo.pos != '記号' else '' for mo in m.morphs]),\n",
    "                  ''.join([mo.surface if mo.pos != '記号' else '' for mo in b[int(m.dst)].morphs]), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVI3yhyuPr6F"
   },
   "source": [
    "#### 43. 名詞を含む文節が動詞を含む文節に係るものを抽出\n",
    "名詞を含む文節が，動詞を含む文節に係るとき，これらをタブ区切り形式で抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1610684604092,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "ISmyNZiSPqFs",
    "outputId": "b4e888b0-5c2c-444d-9ce7-68a67171d137"
   },
   "outputs": [],
   "source": [
    "filename = './ai.ja.txt.parsed'\n",
    "with open(filename, mode='r', encoding='utf-8') as f:\n",
    "    blocks = f.read().split('EOS\\n')\n",
    "blocks = list(filter(lambda x: x != '', blocks))\n",
    "blocks = [parse_cabocha(block) for block in blocks]\n",
    "\n",
    "for b in blocks:\n",
    "    for m in b:\n",
    "        if int(m.dst) > -1:\n",
    "            pre_text = ''.join([mo.surface if mo.pos != '記号' else '' for mo in m.morphs])\n",
    "            pre_pos = [mo.pos for mo in m.morphs]\n",
    "            post_text = ''.join([mo.surface if mo.pos != '記号' else '' for mo in b[int(m.dst)].morphs])\n",
    "            post_pos = [mo.pos for mo in b[int(m.dst)].morphs]\n",
    "            if '名詞' in pre_pos and '動詞' in post_pos:\n",
    "                print(pre_text, post_text, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHxzx5k2SQ7s"
   },
   "source": [
    "#### 44. 係り受け木の可視化\n",
    "与えられた文の係り受け木を有向グラフとして可視化せよ．可視化には，Graphviz等を用いるとよい．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mlvfhg_LSTjf"
   },
   "source": [
    "係り元と係り先の文節のペアを作成し、pydotのgraph_from_edgesに渡すことで、グラフを作成しています。\n",
    "なお、表層形そのままでは1文内に同じ文字列の文節が複数回出てきた場合に区別できないため、末尾にIDを付与して表示しています。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1268,
     "status": "ok",
     "timestamp": 1610684691542,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "UHs79utLSUuj",
    "outputId": "197b501b-ef26-4ed9-c872-a788af0bfb45"
   },
   "outputs": [],
   "source": [
    "filename = './ai.ja.txt.parsed'\n",
    "with open(filename, mode='r', encoding='utf-8') as f:\n",
    "    blocks = f.read().split('EOS\\n')\n",
    "blocks = list(filter(lambda x: x != '', blocks))\n",
    "blocks = [parse_cabocha(block) for block in blocks]\n",
    "\n",
    "pairs = []\n",
    "target = blocks[7]\n",
    "for m in target:\n",
    "    if int(m.dst) > -1:\n",
    "        pre_text = ''.join([mo.surface if mo.pos != '記号' else '' for mo in m.morphs])\n",
    "        post_text = ''.join([mo.surface if mo.pos != '記号' else '' for mo in target[int(m.dst)].morphs])\n",
    "        pairs.append([pre_text, post_text])\n",
    "\n",
    "print(pairs)\n",
    "g = pydot.graph_from_edges(pairs)\n",
    "g.write_png('./ans44.png', prog='dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xpIjrVzS6X0"
   },
   "source": [
    "#### 45. 動詞の格パターンの抽出\n",
    "今回用いている文章をコーパスと見なし，日本語の述語が取りうる格を調査したい． 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力せよ． ただし，出力は以下の仕様を満たすようにせよ．\n",
    "\n",
    "* 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "* 述語に係る助詞を格とする\n",
    "* 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "\n",
    "このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n",
    "* コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "* 「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1093,
     "status": "ok",
     "timestamp": 1610685322495,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "rygwKQbHSWCf"
   },
   "outputs": [],
   "source": [
    "with open('./ans45.txt', 'w') as f:\n",
    "  for sentence in sentences:\n",
    "    for chunk in sentence.chunks:\n",
    "      for morph in chunk.morphs:\n",
    "        if morph.pos == '動詞':  # chunkの左から順番に動詞を探す\n",
    "          cases = []\n",
    "          for src in chunk.srcs:  # 見つけた動詞の係り元chunkから助詞を探す\n",
    "            cases = cases + [morph.surface for morph in sentence.chunks[src].morphs if morph.pos == '助詞']\n",
    "          if len(cases) > 0:  # 助詞が見つかった場合は重複除去後辞書順にソートして出力\n",
    "            cases = sorted(list(set(cases)))\n",
    "            line = '{}\\t{}'.format(morph.base, ' '.join(cases))\n",
    "            print(line, file=f)\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1610685247865,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "vjvqRxKNUmfE"
   },
   "outputs": [],
   "source": [
    "class Morph:\n",
    "    def __init__(self, dc):\n",
    "        self.surface = dc['surface']\n",
    "        self.base = dc['base']\n",
    "        self.pos = dc['pos']\n",
    "        self.pos1 = dc['pos1']\n",
    "\n",
    "\n",
    "class Chunk:\n",
    "    def __init__(self, morphs, dst):\n",
    "        self.morphs = morphs    # 形態素（Morphオブジェクト）のリスト\n",
    "        self.dst = dst          # 係り先文節インデックス番号\n",
    "        self.srcs = []          # 係り元文節インデックス番号のリスト\n",
    "\n",
    "\n",
    "def parse_cabocha(block):\n",
    "    def check_create_chunk(tmp):\n",
    "        if len(tmp) > 0:\n",
    "            c = Chunk(tmp, dst)\n",
    "            res.append(c)\n",
    "            tmp = []\n",
    "        return tmp\n",
    "\n",
    "    res = []\n",
    "    tmp = []\n",
    "    dst = None\n",
    "    for line in block.split('\\n'):\n",
    "        if line == '':\n",
    "            tmp = check_create_chunk(tmp)\n",
    "        elif line[0] == '*':\n",
    "            dst = line.split(' ')[2].rstrip('D')\n",
    "            tmp = check_create_chunk(tmp)\n",
    "        else:\n",
    "            (surface, attr) = line.split('\\t')\n",
    "            attr = attr.split(',')\n",
    "            lineDict = {\n",
    "                'surface': surface,\n",
    "                'base': attr[6],\n",
    "                'pos': attr[0],\n",
    "                'pos1': attr[1]\n",
    "            }\n",
    "            tmp.append(Morph(lineDict))\n",
    "\n",
    "    for i, r in enumerate(res):\n",
    "        res[int(r.dst)].srcs.append(i)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1610685314522,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "wIjBxp7MUUyQ"
   },
   "outputs": [],
   "source": [
    "filename = './ans45.txt'\n",
    "with open(filename, mode='r', encoding='utf-8') as f:\n",
    "    blocks = f.read().split('EOS\\n')\n",
    "blocks = list(filter(lambda x: x != '', blocks))\n",
    "blocks = [parse_cabocha(block) for block in blocks]\n",
    "\n",
    "for b in blocks:\n",
    "    for m in b:\n",
    "        if len(m.srcs) > 0:\n",
    "            pre_morphs = [b[int(s)].morphs for s in m.srcs]\n",
    "            pre_morphs = [list(filter(lambda x: '助詞' in x.pos, pm)) for pm in pre_morphs]\n",
    "            pre_surface = [[p.surface for p in pm] for pm in pre_morphs]\n",
    "            pre_surface = list(filter(lambda x: x != [], pre_surface))\n",
    "            pre_surface = [p[0] for p in pre_surface]\n",
    "            post_base = [mo.base for mo in m.morphs]\n",
    "            post_pos = [mo.pos for mo in m.morphs]\n",
    "            if len(pre_surface) > 0 and '動詞' in post_pos:\n",
    "                print(post_base[0], ' '.join(pre_surface), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1231,
     "status": "ok",
     "timestamp": 1610685316977,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "gud07xM4TCk1"
   },
   "outputs": [],
   "source": [
    "# 確認\n",
    "!cat ./ans45.txt | sort | uniq -c | sort -nr | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1610685034265,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "-OiLZCYSTE5O"
   },
   "outputs": [],
   "source": [
    "!cat ./ans45.txt | grep '行う' | sort | uniq -c | sort -nr | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1769,
     "status": "ok",
     "timestamp": 1610685044091,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "iN_sY23eTytc"
   },
   "outputs": [],
   "source": [
    "!cat ./ans45.txt | grep 'なる' | sort | uniq -c | sort -nr | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 792,
     "status": "ok",
     "timestamp": 1610685051462,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "qzCC-jAKT05t"
   },
   "outputs": [],
   "source": [
    "!cat ./ans45.txt | grep '与える' | sort | uniq -c | sort -nr | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJL9fwbET4c7"
   },
   "source": [
    "#### 46. 動詞の格フレーム情報の抽出\n",
    "45のプログラムを改変し，述語と格パターンに続けて項（述語に係っている文節そのもの）をタブ区切り形式で出力せよ．45の仕様に加えて，以下の仕様を満たすようにせよ．\n",
    "\n",
    "* 項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）\n",
    "* 述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1610685298241,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "LrIenSw1T28J"
   },
   "outputs": [],
   "source": [
    "with open('./ans46.txt', 'w') as f:\n",
    "  for sentence in sentences:\n",
    "    for chunk in sentence.chunks:\n",
    "      for morph in chunk.morphs:\n",
    "        if morph.pos == '動詞':  # chunkの左から順番に動詞を探す\n",
    "          cases = []\n",
    "          modi_chunks = []\n",
    "          for src in chunk.srcs:  # 見つけた動詞の係り元chunkから助詞を探す\n",
    "            case = [morph.surface for morph in sentence.chunks[src].morphs if morph.pos == '助詞']\n",
    "            if len(case) > 0:  # 助詞を含むchunkの場合は助詞と項を取得\n",
    "              cases = cases + case\n",
    "              modi_chunks.append(''.join(morph.surface for morph in sentence.chunks[src].morphs if morph.pos != '記号'))\n",
    "          if len(cases) > 0:  # 助詞が1つ以上見つかった場合は重複除去後辞書順にソートし、項と合わせて出力\n",
    "            cases = sorted(list(set(cases)))\n",
    "            line = '{}\\t{}\\t{}'.format(morph.base, ' '.join(cases), ' '.join(modi_chunks))\n",
    "            print(line, file=f)\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1610685304207,
     "user": {
      "displayName": "yuki kato",
      "photoUrl": "",
      "userId": "08430221927587521076"
     },
     "user_tz": -540
    },
    "id": "Em3vbgZIUzFF"
   },
   "outputs": [],
   "source": [
    "# 確認\n",
    "!cat ./ans46.txt | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQh4jbMEU0n2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOeZbgjwCg27AcwdFK3wI/0",
   "collapsed_sections": [],
   "name": "言語処理100本ノック_2020_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
